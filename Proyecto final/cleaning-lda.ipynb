{
 "cells": [
  {
   "source": [
    "# LIMPIEZA Y LDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR PAQUETES NECESARIOS.\n",
    "import re \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#MATRIX TÉRMINO-DOCUMENTO\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Vectorizador de palabras y DTM\n",
    "from sklearn.decomposition import LatentDirichletAllocation # Modelo de LDA\n",
    "from scipy.sparse import csr_matrix # Para tratar Sparse Matrix\n",
    "\n",
    "#DIVIDIR BASE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#LDA\n",
    "import pyLDAvis \n",
    "from pyLDAvis import sklearn as sklearnlda #EXPORTAR EL MODELO (VISUALIZACIÓN)\n",
    "\n",
    "#WORDCLOUD\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "#Explicación Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMBIAR AQUÍ EL ARCHIVO\n",
    "df1 = pd.read_csv(\"grande_filtrada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_rest , df = train_test_split(df1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-102-d6f43903f998>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-102-d6f43903f998>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    palabras de menos o igual de len(2)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "palabras de menos o igual de len(2)\n"
   ]
  },
  {
   "source": [
    "## Visualización de algunos tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VEAMOS ALGUNOS TWEETS:\n",
    "for i in df[\"tweet\"][30:50]:\n",
    "    print(i)\n",
    "    print(\"\\n-------------------------------\")\n",
    "\n",
    "#EL TRABAJO DE LIMPIEZA ES BASTANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMPIEZA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA GENERAL\n",
    "df.tweet=df.tweet.str.lower()  #mayusulas\n",
    "df.tweet=df.tweet.str.replace('[,\\.!?\\-!?\\\\n\\)\\(\\\\r]', ' ') # Borro Puntuaciones\n",
    "df.tweet=df.tweet.str.replace('[0-9]', ' ') # Quito números\n",
    "df.tweet=df.tweet.str.replace('[^a-zA-Záéíóúñ]+', ' ') #CONSERVAR CARACTERES Y ACENTOS\n",
    "df.tweet=df.tweet.str.replace(' +', ' ') #quito espacios innecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(' .{2} ', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[' en ', ' se ', ' él ', ' el ', ' de ', ' de ', ' en ', ' co ', ' co ']"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "re.findall(' .{2} ', df.tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.tweet:\n",
    "    l = i.split(\" \")\n",
    "    for e in l:\n",
    "        i = i.replace(\"{e}\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACRONIMOS IMPORTANTES\n",
    "#keep america great. kag\n",
    "#make america great again: maga\n",
    "#black lives matter: blm\n",
    "#grand old party: gop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA ESPECIFICA\n",
    "df.tweet=df.tweet.str.replace('biden[A-z]*', '') \n",
    "df.tweet=df.tweet.str.replace('joe[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace('donald[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace('kamala[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace('trump[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace('president[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace('potus[A-z]*', '')\n",
    "df.tweet=df.tweet.str.replace(' .{2} ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA ESPECIFICA DE PALABRAS\n",
    "esp = [\"want\", \"cnn\", \"https\", \"harris\", \"will\", \"just\", \"vote vote\", \"vote early\", \"rally\", \"msnbc\", \"did\", \"let\", \"said\", \"doesn\", \"don\", \"know\", \"plan\", \"said\", \"que\", \"los\", \"really\", \"way\"]\n",
    "\n",
    "for i in esp:\n",
    "    df.tweet=df.tweet.str.replace(i, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "today s somethingthink about commentary days left eeaxm v florida generalelection  real   tdwdstf ert\n\n------------------------------------------------------------------------------\n thanks thisa new beginning for america and for allushave faithyou   ilyjulian election   tom bsdjxv\n\n------------------------------------------------------------------------------\nps thiswhy theguardian and fox news called arizona for  long ago now \n\n------------------------------------------------------------------------------\n lisastark tossing out what remainsgop senators who supported  helping the gop split into a true conservative party while getting a from white supremacists and racistsand taco tuesday tweet about taco tuesday \n\n------------------------------------------------------------------------------\ni think the electionover the more votes counted and this prolongs the more likely   wins what happens next who st t think the courtscongress  side with s too muchstake  \n\n------------------------------------------------------------------------------\na local groupning a parade through ocalasupport  oct the paradebeing sponsoredthe  clubmarion county  tfzospc wpolitics election ocalafl ocalaflorida vote parade marioncountyfl  tacsfcyqtvg\n\n------------------------------------------------------------------------------\npulling the plugstimulus deal againpence gop republican democrat democrats covid covid coronavirus  tqzyfth\n\n------------------------------------------------------------------------------\nhere are the legal challengescampaign has fileddispute the election results  gop elections  tykk b n\n\n------------------------------------------------------------------------------\nit s quite comical when you puttwitter timelineagainsteven twitter thinkss lying  thascyt\n\n------------------------------------------------------------------------------\nthishow thefemocrats believe our police shouldtreated  voters  tas algdz j\n\n------------------------------------------------------------------------------\n tvietor jonfavs danpfeiffer thank you for comingour newyork  phonebanks gettingintroduce jonlovett was the highlightthe  admin forfriendofthepod crookedmedia nyfor  bluewave vote  tyim ztaqnv\n\n------------------------------------------------------------------------------\nso   buy foxnews and make hmmm\n\n------------------------------------------------------------------------------\nnot many thinkan explorer moron asshole cruel bastard cheat sexualpredator serial liar sure but not explorer buthebigly leaving little doubt thatwas beaten explore being more apoplectic with anger thans ever been \n\n------------------------------------------------------------------------------\nwhile i believe   likely win   likely call out his private army canada should work with alliesprepare a strategy for naming and shamingthat happens  tut bm\n\n------------------------------------------------------------------------------\n election results  pennsylvania georgia election waitingfortheresults arizona pennsylvania rwqyy v\n\n------------------------------------------------------------------------------\nwho are you guys voting for   \n\n------------------------------------------------------------------------------\ntvzbquxzmna\n\n------------------------------------------------------------------------------\nlick forthe groundthe church where beloved  maga walked sung every patriots  toqrpaejrup\n\n------------------------------------------------------------------------------\ncan you believe campaigning fornever thought i d see the day  topp wvlkm\n\n------------------------------------------------------------------------------\nrich  liar boilermakers union leader blasts  for claiming union endorsed him thatnot true  tgt bvxe vm\n\n------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#VEAMOS ALGUNOS TWEETS CON LOs CAMBIOS:\n",
    "for i in df[\"tweet\"][30:50]:\n",
    "    print(i)\n",
    "    print(\"\\n------------------------------------------------------------------------------\")\n",
    "\n",
    "#EL TRABAJO DE LIMPIEZA ES BASTANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA DE STOPWORDS\n",
    "# Ahora construiremos la matriz término-documento\n",
    "n_vocab=1500 # máximo tamaño de vocabulario\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=2, max_features=n_vocab, stop_words='english', ngram_range=(1,3)) # Al igual que un modelo, defino el objeto que construirá la matriz\n",
    "tf = tf_vectorizer.fit_transform(df.tweet) # Aplico el objeto a un conjunto de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-99e4ccd7a0e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc_topic_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_word_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m353\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#CONSTRUYO EL MODELO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Esti\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msklearnlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_vectorizer\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# Preparo el modelo y sus resultados para la visualización\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'LDA_{i}.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                     \u001b[1;31m# batch update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m                     self._em_step(X, total_samples=n_samples,\n\u001b[0m\u001b[0;32m    580\u001b[0m                                   batch_update=True, parallel=parallel)\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;31m# E-step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0m\u001b[0;32m    448\u001b[0m                                      parallel=parallel)\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    392\u001b[0m             parallel = Parallel(n_jobs=n_jobs, verbose=max(0,\n\u001b[0;32m    393\u001b[0m                                                            self.verbose - 1))\n\u001b[1;32m--> 394\u001b[1;33m         results = parallel(\n\u001b[0m\u001b[0;32m    395\u001b[0m             delayed(_update_doc_distribution)(X[idx_slice, :],\n\u001b[0;32m    396\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_dirichlet_component_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(4,20):\n",
    "    lda = LatentDirichletAllocation(n_components=i, max_iter=11,doc_topic_prior=0.1, topic_word_prior=0.1, n_jobs=-1,random_state=353, verbose=1) #CONSTRUYO EL MODELO\n",
    "    lda.fit(tf) # Esti\n",
    "    LDAvis_prepared=sklearnlda.prepare(lda, tf, tf_vectorizer ) # Preparo el modelo y sus resultados para la visualización\n",
    "    pyLDAvis.save_html(LDAvis_prepared, f'LDA_{i}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAY QUE ELIMINAR TODAS LAS PALABRAS COMO JOE BIEN Y TRUMO Y SUS VARIANTES, KAMALA, HTTPS, DEBATES O CAMBIARLAS -->ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ELIMINAR PALABRAS CON MENOS DE DOS PALABRAS: LOS, PENDE, POR, DON, SAID, PLAN, YEARS, QUE, DEL, DAY\n",
    "##PERMITIR NGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd006cb5fed7a19db1a3b234843391dc1a69eede94e92f070202b04797e91c1cb37",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}